digraph {
	graph [size="23.55,23.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2456437185008 [label="
 (1, 1, 60, 240, 240)" fillcolor=darkolivegreen1]
	2456545521728 [label=UpsampleTrilinear3DBackward0]
	2456545522016 -> 2456545521728
	2456545522016 [label=ConvolutionBackward0]
	2456545521872 -> 2456545522016
	2456545521872 [label=ConvolutionBackward0]
	2456545522160 -> 2456545521872
	2456545522160 [label=ReluBackward0]
	2456545522352 -> 2456545522160
	2456545522352 [label=ConvolutionBackward0]
	2456545522448 -> 2456545522352
	2456545522448 [label=CatBackward0]
	2456545522640 -> 2456545522448
	2456545522640 [label=ConvolutionBackward0]
	2456545522784 -> 2456545522640
	2456545522784 [label=ConvolutionBackward0]
	2456545522976 -> 2456545522784
	2456545522976 [label=ReluBackward0]
	2456545523168 -> 2456545522976
	2456545523168 [label=ConvolutionBackward0]
	2456545523264 -> 2456545523168
	2456545523264 [label=CatBackward0]
	2456545523456 -> 2456545523264
	2456545523456 [label=ConvolutionBackward0]
	2456545523600 -> 2456545523456
	2456545523600 [label=ConvolutionBackward0]
	2456545523792 -> 2456545523600
	2456545523792 [label=ReluBackward0]
	2456545523984 -> 2456545523792
	2456545523984 [label=ConvolutionBackward0]
	2456545524080 -> 2456545523984
	2456545524080 [label=MaxPool3DWithIndicesBackward0]
	2456545524272 -> 2456545524080
	2456545524272 [label=ConvolutionBackward0]
	2456545524368 -> 2456545524272
	2456545524368 [label=ReluBackward0]
	2456545524560 -> 2456545524368
	2456545524560 [label=ConvolutionBackward0]
	2456545524656 -> 2456545524560
	2456545524656 [label=MaxPool3DWithIndicesBackward0]
	2456545524848 -> 2456545524656
	2456545524848 [label=ConvolutionBackward0]
	2456545524944 -> 2456545524848
	2456545524944 [label=ReluBackward0]
	2456545525136 -> 2456545524944
	2456545525136 [label=ConvolutionBackward0]
	2456545525232 -> 2456545525136
	2456541409744 [label="encoder.encBlocks.0.conv1.weight
 (16, 1, 3, 3, 3)" fillcolor=lightblue]
	2456541409744 -> 2456545525232
	2456545525232 [label=AccumulateGrad]
	2456545525184 -> 2456545525136
	2456541410784 [label="encoder.encBlocks.0.conv1.bias
 (16)" fillcolor=lightblue]
	2456541410784 -> 2456545525184
	2456545525184 [label=AccumulateGrad]
	2456545524896 -> 2456545524848
	2456531857136 [label="encoder.encBlocks.0.conv2.weight
 (16, 16, 3, 3, 3)" fillcolor=lightblue]
	2456531857136 -> 2456545524896
	2456545524896 [label=AccumulateGrad]
	2456545524752 -> 2456545524848
	2456543194384 [label="encoder.encBlocks.0.conv2.bias
 (16)" fillcolor=lightblue]
	2456543194384 -> 2456545524752
	2456545524752 [label=AccumulateGrad]
	2456545524608 -> 2456545524560
	2456541405648 [label="encoder.encBlocks.1.conv1.weight
 (32, 16, 3, 3, 3)" fillcolor=lightblue]
	2456541405648 -> 2456545524608
	2456545524608 [label=AccumulateGrad]
	2456545524464 -> 2456545524560
	2456543269808 [label="encoder.encBlocks.1.conv1.bias
 (32)" fillcolor=lightblue]
	2456543269808 -> 2456545524464
	2456545524464 [label=AccumulateGrad]
	2456545524320 -> 2456545524272
	2456437186448 [label="encoder.encBlocks.1.conv2.weight
 (32, 32, 3, 3, 3)" fillcolor=lightblue]
	2456437186448 -> 2456545524320
	2456545524320 [label=AccumulateGrad]
	2456545524176 -> 2456545524272
	2456437186368 [label="encoder.encBlocks.1.conv2.bias
 (32)" fillcolor=lightblue]
	2456437186368 -> 2456545524176
	2456545524176 [label=AccumulateGrad]
	2456545524032 -> 2456545523984
	2456437186288 [label="encoder.encBlocks.2.conv1.weight
 (64, 32, 3, 3, 3)" fillcolor=lightblue]
	2456437186288 -> 2456545524032
	2456545524032 [label=AccumulateGrad]
	2456545523888 -> 2456545523984
	2456437186208 [label="encoder.encBlocks.2.conv1.bias
 (64)" fillcolor=lightblue]
	2456437186208 -> 2456545523888
	2456545523888 [label=AccumulateGrad]
	2456545523744 -> 2456545523600
	2456437186128 [label="encoder.encBlocks.2.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	2456437186128 -> 2456545523744
	2456545523744 [label=AccumulateGrad]
	2456545523696 -> 2456545523600
	2456437186048 [label="encoder.encBlocks.2.conv2.bias
 (64)" fillcolor=lightblue]
	2456437186048 -> 2456545523696
	2456545523696 [label=AccumulateGrad]
	2456545523552 -> 2456545523456
	2456531856336 [label="decoder.upconvs.0.weight
 (64, 32, 2, 2, 2)" fillcolor=lightblue]
	2456531856336 -> 2456545523552
	2456545523552 [label=AccumulateGrad]
	2456545523504 -> 2456545523456
	2456541421632 [label="decoder.upconvs.0.bias
 (32)" fillcolor=lightblue]
	2456541421632 -> 2456545523504
	2456545523504 [label=AccumulateGrad]
	2456545523408 -> 2456545523264
	2456545523408 [label=UpsampleTrilinear3DBackward0]
	2456545524272 -> 2456545523408
	2456545523216 -> 2456545523168
	2456491220880 [label="decoder.dec_blocks.0.conv1.weight
 (32, 64, 3, 3, 3)" fillcolor=lightblue]
	2456491220880 -> 2456545523216
	2456545523216 [label=AccumulateGrad]
	2456545523072 -> 2456545523168
	2456436681040 [label="decoder.dec_blocks.0.conv1.bias
 (32)" fillcolor=lightblue]
	2456436681040 -> 2456545523072
	2456545523072 [label=AccumulateGrad]
	2456545522928 -> 2456545522784
	2456436682640 [label="decoder.dec_blocks.0.conv2.weight
 (32, 32, 3, 3, 3)" fillcolor=lightblue]
	2456436682640 -> 2456545522928
	2456545522928 [label=AccumulateGrad]
	2456545522880 -> 2456545522784
	2456436680960 [label="decoder.dec_blocks.0.conv2.bias
 (32)" fillcolor=lightblue]
	2456436680960 -> 2456545522880
	2456545522880 [label=AccumulateGrad]
	2456545522736 -> 2456545522640
	2456545302624 [label="decoder.upconvs.1.weight
 (32, 16, 2, 2, 2)" fillcolor=lightblue]
	2456545302624 -> 2456545522736
	2456545522736 [label=AccumulateGrad]
	2456545522688 -> 2456545522640
	2456511020304 [label="decoder.upconvs.1.bias
 (16)" fillcolor=lightblue]
	2456511020304 -> 2456545522688
	2456545522688 [label=AccumulateGrad]
	2456545522592 -> 2456545522448
	2456545522592 [label=UpsampleTrilinear3DBackward0]
	2456545524848 -> 2456545522592
	2456545522400 -> 2456545522352
	2456436679520 [label="decoder.dec_blocks.1.conv1.weight
 (16, 32, 3, 3, 3)" fillcolor=lightblue]
	2456436679520 -> 2456545522400
	2456545522400 [label=AccumulateGrad]
	2456545522256 -> 2456545522352
	2456436679760 [label="decoder.dec_blocks.1.conv1.bias
 (16)" fillcolor=lightblue]
	2456436679760 -> 2456545522256
	2456545522256 [label=AccumulateGrad]
	2456545522112 -> 2456545521872
	2456436680080 [label="decoder.dec_blocks.1.conv2.weight
 (16, 16, 3, 3, 3)" fillcolor=lightblue]
	2456436680080 -> 2456545522112
	2456545522112 [label=AccumulateGrad]
	2456545521776 -> 2456545521872
	2456436680640 [label="decoder.dec_blocks.1.conv2.bias
 (16)" fillcolor=lightblue]
	2456436680640 -> 2456545521776
	2456545521776 [label=AccumulateGrad]
	2456545522064 -> 2456545522016
	2456544771664 [label="head.weight
 (1, 16, 1, 1, 1)" fillcolor=lightblue]
	2456544771664 -> 2456545522064
	2456545522064 [label=AccumulateGrad]
	2456545521968 -> 2456545522016
	2456545334192 [label="head.bias
 (1)" fillcolor=lightblue]
	2456545334192 -> 2456545521968
	2456545521968 [label=AccumulateGrad]
	2456545521728 -> 2456437185008
}
